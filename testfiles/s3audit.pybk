import boto3
import botocore
import csv
import sys

def audit_s3_buckets(profile_name):
    # Start the session with the provided AWS profile
    session = boto3.Session(profile_name=profile_name)
    s3_client = session.client('s3')

    # Prepare the CSV file
    with open('s3_audit.csv', 'w', newline='') as f:
        writer = csv.writer(f)
        # Write CSV header
        writer.writerow(["Bucket Name", "Storage Class", "Versioning", "Server Access Logging", 
                         "Lifecycle Rule Name", "Lifecycle Rule Status"])

        # Get the list of S3 buckets
        buckets_response = s3_client.list_buckets()
        buckets = buckets_response.get("Buckets", [])

        # Iterate through each bucket and fetch the requested details
        for bucket in buckets:
            bucket_name = bucket.get("Name", "N/A")
            
            # Default values for each column
            storage_class = "N/A"  # S3 buckets generally do not have bucket-wide storage classes; this field can be updated
            versioning_status = "Disabled"
            logging_status = "Disabled"
            lifecycle_rule_name = "None"
            lifecycle_rule_status = "None"

            # Fetch versioning status
            try:
                versioning_response = s3_client.get_bucket_versioning(Bucket=bucket_name)
                versioning_status = versioning_response.get("Status", "Disabled")
            except botocore.exceptions.ClientError:
                versioning_status = "Error"

            # Fetch server access logging configuration
            try:
                logging_response = s3_client.get_bucket_logging(Bucket=bucket_name)
                if "LoggingEnabled" in logging_response:
                    logging_status = "Enabled"
                else:
                    logging_status = "Disabled"
            except botocore.exceptions.ClientError:
                logging_status = "Error"

            # Fetch lifecycle configuration
            try:
                lifecycle_response = s3_client.get_bucket_lifecycle_configuration(Bucket=bucket_name)
                lifecycle_rules = lifecycle_response.get("Rules", [])
                if lifecycle_rules:
                    lifecycle_rule_name = lifecycle_rules[0].get("ID", "Unnamed")
                    lifecycle_rule_status = lifecycle_rules[0].get("Status", "Unknown")
            except botocore.exceptions.ClientError:
                lifecycle_rule_name = "Error"
                lifecycle_rule_status = "Error"

            # Write the bucket details to the CSV file
            writer.writerow([bucket_name, storage_class, versioning_status, logging_status, 
                             lifecycle_rule_name, lifecycle_rule_status])

    print("S3 bucket audit completed. Output saved to s3_audit.csv")

if __name__ == "__main__":
    # Command-line arguments handling
    import sys
    if len(sys.argv) != 2:
        print("Usage: python3 s3audit.py <AWS_PROFILE>")
        sys.exit(1)

    PROFILE_NAME = sys.argv[1]  # Get the profile name from the command-line argument
    try:
        audit_s3_buckets(PROFILE_NAME)
    except botocore.exceptions.NoCredentialsError:
        print("No credentials found. Please ensure your profile is set up correctly in .aws/config.")

